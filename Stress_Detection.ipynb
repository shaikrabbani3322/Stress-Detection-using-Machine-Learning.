{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"g3UoCPJyvvBn"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","df=pd.read_csv('/content/drive/MyDrive/stress.csv')\n","df.head()\n","\n","df.describe()\n","\n","df.isnull().sum()\n","\n","import nltk\n","import re\n","from nltk. corpus import stopwords\n","import string\n","nltk. download( 'stopwords' )\n","stemmer = nltk. SnowballStemmer(\"english\")\n","stopword=set (stopwords . words ( 'english' ))\n","\n","def clean(text):\n","    text = str(text) . lower()  #returns a string where all characters are lower case. Symbols and Numbers are ignored.\n","    text = re. sub('\\[.*?\\]',' ',text)  #substring and returns a string with replaced values.\n","    text = re. sub('https?://\\S+/www\\. \\S+', ' ', text)#whitespace char with pattern\n","    text = re. sub('<. *?>+', ' ', text)#special char enclosed in square brackets\n","    text = re. sub(' [%s]' % re. escape(string. punctuation), ' ', text)#eliminate punctuation from string\n","    text = re. sub(' \\n',' ', text)\n","    text = re. sub(' \\w*\\d\\w*' ,' ', text)#word character ASCII punctuation\n","    text = [word for word in text. split(' ') if word not in stopword]  #removing stopwords\n","    text =\" \". join(text)\n","    text = [stemmer . stem(word) for word in text. split(' ') ]#remove morphological affixes from words\n","    text = \" \". join(text)\n","    return text\n","df [ \"text\"] = df[\"text\"]. apply(clean)\n","\n","import matplotlib. pyplot as plt\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","text = \" \". join(i for i in df. text)\n","stopwords = set (STOPWORDS)\n","wordcloud = WordCloud( stopwords=stopwords,background_color=\"white\") . generate(text)\n","plt. figure(figsize=(10, 10) )\n","plt. imshow(wordcloud )\n","plt. axis(\"off\")\n","plt. show( )\n","\n","\n","from sklearn. feature_extraction. text import CountVectorizer\n","from sklearn. model_selection import train_test_split\n","\n","x = np.array (df[\"text\"])\n","y = np.array (df[\"label\"])\n","\n","cv = CountVectorizer ()\n","X = cv. fit_transform(x)\n","print(X)\n","xtrain, xtest, ytrain, ytest = train_test_split(X, y,test_size=0.33)\n","\n","from sklearn.naive_bayes import BernoulliNB\n","model=BernoulliNB()\n","model.fit(xtrain,ytrain)\n","\n","user=input(\"Enter the text\")\n","data=cv.transform([user]).toarray()\n","output=model.predict(data)\n","print(output)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNJLZuwtOjby+xN/j2R/vl6","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
